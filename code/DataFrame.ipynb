{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "is the most popular Python library for data analysis, help dealing with data set and it will extract the data from that CSV into a DataFrame.\n",
    "\n",
    "<img src='pandas.png'>\n",
    "\n",
    "### IMPORT OF Pandas :-\n",
    "- import `pandas` as `np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series & DataFrame\n",
    "\n",
    "##### 1. Series:\n",
    " is considered column in an excel sheet.\n",
    "##### 2. DataFrame:\n",
    " is a table, datasets arrange in rows and columns,\n",
    "###### If a DataFrame is a table, a Series is a list.\n",
    "\n",
    "<img src='series-and-dataframe.width-1200.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create series\n",
    "- created by loading the datasets from existing storage like CSV file, and Excel file. \n",
    "- can be created from the lists, dictionary, and from a scalar value etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([3,2,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index and name\n",
    "pd.Series([3,2,0,1], index=['Day_1', 'Day_2','Day_3','Day_4'], name='Appels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame\n",
    "- can be created is an Empty Dataframe by calling a dataframe constructor.\n",
    "- can be created from dict narray / lists ,Lists and List of Dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict\n",
    "data = {\n",
    "    'apples': [3, 2, 0, 1], \n",
    "    'oranges': [0, 3, 7, 2]\n",
    "}\n",
    "# keys are the column names \n",
    "# values are a list of entries\n",
    "#then pass it to the pandas DataFrame constructor\n",
    "mydata_frame= pd.DataFrame(data)\n",
    "mydata_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index ( row labels)\n",
    "import pandas as pd\n",
    "mydata_frame= pd.DataFrame(data,index=['Day_1', 'Day_2','Day_3','Day_4'])\n",
    "mydata_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q: create a DataFrame by passing a list of dictionaries and the row indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data files\n",
    "most of the time, we won't actually be creating our own data by hand. Instead, we'll be working with data that already exists.\n",
    "Data can be stored in different forms and formats. as(txt,csv,Excel...)\n",
    "\n",
    "- we can read data.csv (Comma-Separated Values) into a DataFrame by `pd.read_csv()` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "INTRO: DATA SET\n",
    "Medium is one of the most famous tools for spreading knowledge about almost any field. \n",
    "It is widely used to published articles on ML, AI, and data science. \n",
    "This dataset is the collection of about 338 articles in such fields\n",
    "\n",
    "'''\n",
    "data_f=pd.read_csv('articles.csv')\n",
    "data_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can examine the contents of DataFrame using the ` head() ` command , which display the first five rows by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use ` tail() `To see the last five rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove index\n",
    "data_f=pd.read_csv('articles.csv', index_col=0) # set index by columns (using name or index)\n",
    "# we can use set_index()\n",
    "#data_f.set_index('title')\n",
    "data_f.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Understanding Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using describe() \"summary function\"\n",
    "data_f.reading_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info() function is used to get summary of the dataframe\n",
    "data_f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.author.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a list of unique values we can use the unique() function\n",
    "data_f.author.unique()\n",
    "# note : Although repeated 'Justin Lee' 5 times , There are in unique array\n",
    "# Each repeated value appears once in unique array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see a list of unique values and how often they occur in the dataset\n",
    "data_f.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q:Display a summary of the basic information about  data ('medium_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Data\n",
    "Selecting specific values of a pandas DataFrame or Series to work on is in any data operation you'll run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f=pd.read_csv('articles.csv')\n",
    "data_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.methode (Columns is attribute of object)\n",
    "In Python, we can access the property of an object by accessing it as an attribute, Columns in a pandas DataFrame work in much the same way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.reading_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. methode (dataframe is dictionary)\n",
    "in Python dictionary, we can access its values using the indexing ([]) operator.\n",
    "\n",
    "- Note:\n",
    "the indexing operator [] does have the advantage that it can handle column names with reserved characters in them (e.g. if we had a `Publishing house` column, `dataframe.Publishing house` wouldn't work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f['claps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Access entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f['claps'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Accessor operators `loc`  and `iloc` \n",
    "\n",
    "- `iloc` we treat the dataset like a big matrix (a list of lists) , select data based on its numerical position in the data, this is called 'Index-based selection'.\n",
    "\n",
    "- `loc` uses the information in the indices and ignores the dataset's indices, this is called ' label-based selection'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Select just the 'subtitle' and 'date' columns from the DataFrame `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conditional selection\n",
    "For example, what if we want to filter our articles to show only articles wirtten by Daniel Simmons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f=pd.read_csv('articles.csv')\n",
    "data_f.author=='Daniel Simmons'# return Series of True/False booleans based on the author of each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count them\n",
    "sum(data_f.author=='Daniel Simmons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.loc[data_f.author=='Daniel Simmons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.title=='Chatbots were the next big thing: what happened? – The Startup – Medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_f.title=='Chatbots were the next big thing: what happened? – The Startup – Medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show them\n",
    "data_f.loc[data_f.title=='Chatbots were the next big thing: what happened? – The Startup – Medium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_f['title']=='Chatbots were the next big thing: what happened? – The Startup – Medium').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.loc[(data_f.claps=='8.3K')&(data_f.reading_time==11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.loc[data_f.reading_time==11].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.loc[data_f.claps=='8.3K'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Built-in conditional selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use isin() \n",
    "data_f.loc[data_f.reading_time.isin([5])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Filtering data using query() method\n",
    "taking expression to filter data, return Filtered Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.query('reading_time > 5') # return articles have reading time greater than 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** in data ('medium_data.csv')\n",
    "- count of only the articles where the number of claps is greater than 1000.\n",
    "- Select only the articles that it is publicated by Towards Data Science where the number of claps is greater than 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Assigning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_f['num_comments']=np.random.randint(1,50,len(data_f))\n",
    "data_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** change value of column `id`  into numbers that has mean = 0.0 in data ('medium_data.csv')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Drop specified labels from rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can remove rows or columns from data by drop()\n",
    "data_f.drop(['num_comments'], axis=1,inplace=True)\n",
    "data_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maps\n",
    "It is possible to iterate over a DataFrame or Series as you would with a list, but doing so — especially on large datasets — is very slow.\n",
    "\n",
    "map is function that takes one set of values and \"maps\" them to another set of values.\n",
    "We can transform data from the format it is in now to the format that we want it using Maps.\n",
    "\n",
    "\n",
    "- `apply` method can be applied both to series and dataframes,if we want to transform a whole DataFrame by calling a custom method on each row.\n",
    "\n",
    "###### NOTE:\n",
    " `apply` don't modify the original data they're called on\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(strk):\n",
    "    return float(strk[:-1]) if 'K'in strk else float(strk)/1000.0\n",
    "    \n",
    "str_to_int('2.8K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.loc[:,'claps'].apply(str_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int2(row):\n",
    "    return float(row.claps[:-1]) if 'K'in row.claps else float(row.claps)/1000.0\n",
    "\n",
    "\n",
    "data_f.apply(str_to_int, axis=1)\n",
    "#data_f.map(str_to_int, axis=1) Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping\n",
    "`groupby()` function is used to split the data into groups based on some criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.groupby('author').sum() #sum values of reading_time for each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q: Get the least reading time in each title articles category in data ('medium_data.csv')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Combining:\n",
    "we use `concat()` to combine two dataframe and Given a list of dataframe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f2=pd.read_csv('medium_data.csv',nrows=100)# set The same number of rows of data_f ===> data_f.shape[0]\n",
    "data_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data=pd.concat([data_f, data_f2])\n",
    "article_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dealing with Missing Data \n",
    "Entries missing values are given the value NaN.\n",
    "\n",
    "To select NaN entries we can use `isnull()` .\n",
    "\n",
    "To remove all columns or rows that contain least one missing value we can use `dropna()` .\n",
    "\n",
    "To fill in missing values in a dataframe OR specify what we want the NaN values to be replaced with we can use `fillna()` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#article_data.dropna() #remove all the rows that contain a missing value\n",
    "article_data.dropna(axis=1) #remove all columns with at least one missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.loc[:,['id','url','responses','publication','date']].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Replace Missing Data in `subtitle` by text='no subtitle'  in data ('medium_data.csv')."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
